{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 1: Training using active learning and pseudo labeling",
   "id": "a2e580d8c08f6f94"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T00:14:01.802950Z",
     "start_time": "2024-12-11T00:14:00.500660Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:14:02.739860Z",
     "start_time": "2024-12-11T00:14:02.530183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../dataset/yelp_pseudo_features.csv\")\n",
    "df.tail()"
   ],
   "id": "42d983fdfd977b17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      business_id date review_id  stars  \\\n",
       "10495         NaN  NaN       NaN      1   \n",
       "10496         NaN  NaN       NaN      1   \n",
       "10497         NaN  NaN       NaN      1   \n",
       "10498         NaN  NaN       NaN      1   \n",
       "10499         NaN  NaN       NaN      1   \n",
       "\n",
       "                                                    text type user_id  cool  \\\n",
       "10495  Dining here guarantees you’ll leave with a les...  NaN     NaN   NaN   \n",
       "10496  This amusement park feels like an endurance te...  NaN     NaN   NaN   \n",
       "10497  The library inspires nostalgia, mostly for bet...  NaN     NaN   NaN   \n",
       "10498  The spa offers relaxation, though mostly for y...  NaN     NaN   NaN   \n",
       "10499  You’ll leave this bar with stories to tell, mo...  NaN     NaN   NaN   \n",
       "\n",
       "       useful  funny  scores_pooling_mean  scores_pooling_max  \\\n",
       "10495     NaN    NaN             -0.05160             -0.0516   \n",
       "10496     NaN    NaN              0.73510              0.7351   \n",
       "10497     NaN    NaN              0.44040              0.4404   \n",
       "10498     NaN    NaN              0.26335              0.5267   \n",
       "10499     NaN    NaN             -0.26415             -0.0516   \n",
       "\n",
       "       scores_pooling_min  scores_pooling_std  scores_pooling_sum  \\\n",
       "10495             -0.0516             0.00000             -0.0516   \n",
       "10496              0.7351             0.00000              0.7351   \n",
       "10497              0.4404             0.00000              0.8808   \n",
       "10498              0.0000             0.26335              0.5267   \n",
       "10499             -0.4767             0.21255             -0.5283   \n",
       "\n",
       "         scores_concat  scores_shift_psm  scores_shift_ratio  \n",
       "10495          -0.0516          0.000000                 0.0  \n",
       "10496           0.7351          0.000000                 0.0  \n",
       "10497    0.4404|0.4404          0.000000                 0.0  \n",
       "10498       0.5267|0.0          0.277413                 1.0  \n",
       "10499  -0.0516|-0.4767          0.000000                 0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>scores_pooling_mean</th>\n",
       "      <th>scores_pooling_max</th>\n",
       "      <th>scores_pooling_min</th>\n",
       "      <th>scores_pooling_std</th>\n",
       "      <th>scores_pooling_sum</th>\n",
       "      <th>scores_concat</th>\n",
       "      <th>scores_shift_psm</th>\n",
       "      <th>scores_shift_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Dining here guarantees you’ll leave with a les...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.05160</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>This amusement park feels like an endurance te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73510</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>The library inspires nostalgia, mostly for bet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.44040</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>0.4404|0.4404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>The spa offers relaxation, though mostly for y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26335</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.26335</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.5267|0.0</td>\n",
       "      <td>0.277413</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>You’ll leave this bar with stories to tell, mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.26415</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.21255</td>\n",
       "      <td>-0.5283</td>\n",
       "      <td>-0.0516|-0.4767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:14:04.496043Z",
     "start_time": "2024-12-11T00:14:04.472948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mark the generated data as positive.\n",
    "df[\"is_generated\"] = df[\"review_id\"].isna().astype(int)"
   ],
   "id": "8d7e56d9844d2a29",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:14:06.379150Z",
     "start_time": "2024-12-11T00:14:06.362113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random sampling the initial samples (30 positive and 30 negatives)\n",
    "real_samples = df[df[\"is_generated\"] == 0].sample(30, random_state=42)\n",
    "generated_samples = df[df[\"is_generated\"] == 1].sample(30, random_state=42)\n",
    "\n",
    "# Selected features from previous step:\n",
    "feature_cols = [\"scores_pooling_mean\", \"scores_pooling_max\", \"scores_pooling_min\", \"scores_pooling_std\",\n",
    "                \"scores_pooling_sum\", \"scores_shift_psm\", \"scores_shift_ratio\"]\n",
    "\n",
    "# Construction the training set:\n",
    "initial_samples = pd.concat([real_samples, generated_samples])\n",
    "X_train = initial_samples[feature_cols]\n",
    "y_train = initial_samples[\"is_generated\"]\n",
    "remaining_data = df.drop(initial_samples.index)\n"
   ],
   "id": "aabbe574065cd00b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Active Learning",
   "id": "a4f7b77c1fe8b0a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:41:15.284548Z",
     "start_time": "2024-12-11T00:41:15.265960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_active_learning(X_train, y_train, remaining_samples, target_positive_cnt=500, step=50):\n",
    "    print(remaining_samples.shape)\n",
    "    iteration = 0\n",
    "    positive_cnt = 30\n",
    "    classifier = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "    while positive_cnt < target_positive_cnt:\n",
    "        iteration += 1\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        X_remaining = remaining_samples[feature_cols]\n",
    "        remaining_samples[\"probability\"] = classifier.predict_proba(X_remaining)[:, 1]\n",
    "\n",
    "        sorted_samples = remaining_samples.sort_values(by=\"probability\", ascending=False)\n",
    "        high_conf_samples = sorted_samples.head(step)\n",
    "        low_conf_samples = sorted_samples.tail(step)\n",
    "\n",
    "        if high_conf_samples.empty and low_conf_samples.empty:\n",
    "            break\n",
    "\n",
    "        X_train = pd.concat([X_train, high_conf_samples[feature_cols], low_conf_samples[feature_cols]])\n",
    "\n",
    "        ##### Querying the actual labels #####\n",
    "        y_high_conf = high_conf_samples[\"is_generated\"]\n",
    "        y_low_conf = low_conf_samples[\"is_generated\"]\n",
    "        y_train = pd.concat([y_train, y_high_conf, y_low_conf])\n",
    "\n",
    "        remaining_samples = remaining_samples.drop(index=high_conf_samples.index)\n",
    "        remaining_samples = remaining_samples.drop(index=low_conf_samples.index)\n",
    "\n",
    "        positive_cnt += high_conf_samples.shape[0]\n",
    "        print(f\"Iteration {iteration}, cur positive samples count: {positive_cnt}\")\n",
    "\n",
    "    return classifier"
   ],
   "id": "339187d2a147009c",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:45:05.154078Z",
     "start_time": "2024-12-11T00:45:04.121693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = train_active_learning(X_train, y_train, remaining_data, target_positive_cnt=500, step=50)\n",
    "\n",
    "# Final top_500 results with the highest probability\n",
    "df[\"probability\"] = classifier.predict_proba(df[feature_cols])[:, 1]\n",
    "top_500_samples = df.sort_values(by=\"probability\", ascending=False).head(500)\n",
    "\n",
    "output = top_500_samples[[\"probability\", \"is_generated\", \"text\"]]\n",
    "\n",
    "output.to_csv(\"../output/top500_active_learning.csv\", index=False)\n",
    "\n",
    "# Calculating raw Precision@500 without double check from GPT\n",
    "precision_at_500 = top_500_samples[\"is_generated\"].sum() / len(top_500_samples)\n",
    "print(f\"Precision@500: {precision_at_500:.4f}\")"
   ],
   "id": "e6048e9a48607742",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10440, 20)\n",
      "Iteration 1, cur positive samples count: 80\n",
      "Iteration 2, cur positive samples count: 130\n",
      "Iteration 3, cur positive samples count: 180\n",
      "Iteration 4, cur positive samples count: 230\n",
      "Iteration 5, cur positive samples count: 280\n",
      "Iteration 6, cur positive samples count: 330\n",
      "Iteration 7, cur positive samples count: 380\n",
      "Iteration 8, cur positive samples count: 430\n",
      "Iteration 9, cur positive samples count: 480\n",
      "Iteration 10, cur positive samples count: 530\n",
      "Precision@500: 0.5800\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Pseudo labeling\n",
   "id": "f1d83693c4c6ec9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:42:12.515622Z",
     "start_time": "2024-12-11T00:42:12.491008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_pseudo_labeling(X_train, y_train, remaining_samples, target_positive_cnt=500, step=50):\n",
    "    print(remaining_samples.shape)\n",
    "    iteration = 0\n",
    "    positive_cnt = 30\n",
    "    classifier = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "    while positive_cnt < target_positive_cnt:\n",
    "        iteration += 1\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        X_remaining = remaining_samples[feature_cols]\n",
    "        remaining_samples[\"probability\"] = classifier.predict_proba(X_remaining)[:, 1]\n",
    "\n",
    "        sorted_samples = remaining_samples.sort_values(by=\"probability\", ascending=False)\n",
    "        high_conf_samples = sorted_samples.head(step)\n",
    "        low_conf_samples = sorted_samples.tail(step)\n",
    "\n",
    "        if high_conf_samples.empty and low_conf_samples.empty:\n",
    "            break\n",
    "\n",
    "        X_train = pd.concat([X_train, high_conf_samples[feature_cols], low_conf_samples[feature_cols]])\n",
    "\n",
    "        ##### Assigning the pseudo labels #####\n",
    "        y_high_conf = pd.Series(1, index=high_conf_samples.index)\n",
    "        y_low_conf = pd.Series(0, index=low_conf_samples.index)\n",
    "        y_train = pd.concat([y_train, y_high_conf, y_low_conf])\n",
    "\n",
    "        remaining_samples = remaining_samples.drop(index=high_conf_samples.index)\n",
    "        remaining_samples = remaining_samples.drop(index=low_conf_samples.index)\n",
    "\n",
    "        positive_cnt += high_conf_samples.shape[0]\n",
    "        print(f\"Iteration {iteration}, cur positive samples count: {positive_cnt}\")\n",
    "\n",
    "    return classifier\n"
   ],
   "id": "a711966d458ea943",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:45:01.421269Z",
     "start_time": "2024-12-11T00:45:00.668878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = train_pseudo_labeling(X_train, y_train, remaining_data, target_positive_cnt=500, step=50)\n",
    "\n",
    "# Final top_500 results with the highest probability\n",
    "df[\"probability\"] = classifier.predict_proba(df[feature_cols])[:, 1]\n",
    "top_500_samples = df.sort_values(by=\"probability\", ascending=False).head(500)\n",
    "\n",
    "output = top_500_samples[[\"probability\", \"is_generated\", \"text\"]]\n",
    "\n",
    "output.to_csv(\"../output/top500_pseudo_labeling.csv\", index=False)\n",
    "\n",
    "# Calculating raw Precision@500 without double check from GPT\n",
    "precision_at_500 = top_500_samples[\"is_generated\"].sum() / len(top_500_samples)\n",
    "print(f\"Precision@500: {precision_at_500:.4f}\")"
   ],
   "id": "a4b68ec38c2ddfa7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10440, 20)\n",
      "Iteration 1, cur positive samples count: 80\n",
      "Iteration 2, cur positive samples count: 130\n",
      "Iteration 3, cur positive samples count: 180\n",
      "Iteration 4, cur positive samples count: 230\n",
      "Iteration 5, cur positive samples count: 280\n",
      "Iteration 6, cur positive samples count: 330\n",
      "Iteration 7, cur positive samples count: 380\n",
      "Iteration 8, cur positive samples count: 430\n",
      "Iteration 9, cur positive samples count: 480\n",
      "Iteration 10, cur positive samples count: 530\n",
      "Precision@500: 0.3180\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 2: evaluating the results using LLM (GPT-4o) as ground truth.",
   "id": "b3e12f1fc2b08170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:47:28.802404Z",
     "start_time": "2024-12-11T00:47:28.773856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "api_key = \"sk\"\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", api_key))\n",
    "\n",
    "\n",
    "def gpt_review_check(df, verbose=False):\n",
    "    df[\"gpt_check\"] = 0\n",
    "    for idx, row in tqdm(df[df[\"is_generated\"] == 0].iterrows()):\n",
    "        review_text = row[\"text\"]\n",
    "\n",
    "        prompt = f\"Review text:{review_text}. Does this review seem sarcastic? Answer 'Yes' or 'No'.\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\",\n",
    "                 \"content\": \"You are an assistant tasked with determining whether a given Yelp review is sarcastic or not. Sample sarcastic review may like \\\"The server was efficient at ignoring us.\\\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        response_text = response.choices[0].message.content.strip().lower()\n",
    "        if \"yes\" in response_text:\n",
    "            df.at[idx, \"gpt_check\"] = 1\n",
    "\n",
    "        if verbose:\n",
    "            print(\"-----------------------------------------\")\n",
    "            print(\"Check result:\", response_text)\n",
    "            print(review_text)\n",
    "    return df"
   ],
   "id": "c891dfb2e57852f4",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:53:09.445402Z",
     "start_time": "2024-12-11T00:53:09.424777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_precision_at_k(df, k):\n",
    "    df = df.sort_values(by=\"probability\", ascending=False).head(k)\n",
    "    positive_samples = ((df[\"is_generated\"] == 1) | (df[\"gpt_check\"] == 1)).sum()\n",
    "    p_at_k = positive_samples / k\n",
    "    print(f\"Precision@{k}: {p_at_k:.4f}\")\n",
    "    return p_at_k\n",
    "\n",
    "\n",
    "def eval_results(file_path):\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Evaluating result:\", file_path)\n",
    "    df_res = pd.read_csv(file_path)\n",
    "    df_res = gpt_review_check(df_res, verbose=False)\n",
    "    for k in [10, 20, 30, 50, 100, 200, 500]:\n",
    "        calculate_precision_at_k(df_res, k)"
   ],
   "id": "5449edd5eb5d922",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:54:57.708642Z",
     "start_time": "2024-12-11T00:53:17.030826Z"
    }
   },
   "cell_type": "code",
   "source": "eval_results(\"../output/top500_active_learning.csv\")",
   "id": "194e137342d6cc6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Evaluating result: ../output/top500_active_learning.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [01:40,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 1.0000\n",
      "Precision@20: 1.0000\n",
      "Precision@30: 0.9667\n",
      "Precision@50: 0.9800\n",
      "Precision@100: 0.9800\n",
      "Precision@200: 0.8800\n",
      "Precision@500: 0.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:58:08.084700Z",
     "start_time": "2024-12-11T00:55:41.347006Z"
    }
   },
   "cell_type": "code",
   "source": "eval_results(\"../output/top500_pseudo_labeling.csv\")",
   "id": "366fa98094ce9bf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Evaluating result: ../output/top500_pseudo_labeling.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "341it [02:26,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.5000\n",
      "Precision@20: 0.5000\n",
      "Precision@30: 0.4333\n",
      "Precision@50: 0.4800\n",
      "Precision@100: 0.4300\n",
      "Precision@200: 0.4200\n",
      "Precision@500: 0.3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 81
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
